{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ac9c73-4a18-4d78-80bc-165b3dbd6307",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = pd.read_excel(r\"E:\\LCMs-descriptors.xlsx\")\n",
    "\n",
    "names = data[\"Name\"]\n",
    "\n",
    "if \"label\" in data.columns:\n",
    "    y = data[\"label\"].values\n",
    "else:\n",
    "    y = data[\"Category\"].map({\n",
    "        \"acceptable\": 0,\n",
    "        \"potential\": 1,\n",
    "        \"unacceptable\": 2\n",
    "    }).values\n",
    "\n",
    "X = data.iloc[:, 4:]\n",
    "feature_names = X.columns\n",
    "\n",
    "vt = VarianceThreshold(threshold=0.0)\n",
    "X_var = vt.fit_transform(X)\n",
    "features_var = feature_names[vt.get_support()]\n",
    "\n",
    "corr_matrix = X[features_var].corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.65)]\n",
    "X_uncorr = X[features_var].drop(columns=to_drop)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "rf.fit(X_uncorr, y)\n",
    "\n",
    "sfm = SelectFromModel(rf, threshold=\"median\", prefit=True) \n",
    "X_selected = sfm.transform(X_uncorr)\n",
    "features_selected = list(X_uncorr.columns[sfm.get_support()])\n",
    "\n",
    "features_selected = [f for f in X.columns if f in features_selected]\n",
    "\n",
    "final_df = pd.concat([names, pd.Series(y, name=\"label\"), X[features_selected]], axis=1)\n",
    "\n",
    "output_path = r\"E:\\LCMs-Features-Selected(final).xlsx\"\n",
    "final_df.to_excel(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df9e595-6212-469e-8945-78d2937265b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "import random\n",
    "import math\n",
    "\n",
    "X = X[features_selected].values  \n",
    "y = y                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e297f6a-46fa-4f8a-be27-43ff86cde95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "import random\n",
    "\n",
    "seed = 40\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42, stratify=y)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val   = scaler.transform(X_val)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "train_min = scaler.data_min_\n",
    "train_max = scaler.data_max_\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(X_val_tensor, y_val_tensor), batch_size=16, shuffle=False)\n",
    "\n",
    "class RealFormerClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, d_model=32, nhead=4, num_layers=1, dropout=0.3):\n",
    "        super(RealFormerClassifier, self).__init__()\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(d_model, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_proj(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.mean(dim=1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "num_classes = len(np.unique(y))\n",
    "model = RealFormerClassifier(input_dim=X_train.shape[1], num_classes=num_classes)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "epochs = 500\n",
    "best_val_acc = 0\n",
    "patience = 100\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        preds = model(batch_X)\n",
    "        loss = criterion(preds, batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_logits = model(X_val_tensor)\n",
    "        val_pred = val_logits.argmax(dim=1).cpu().detach().numpy()\n",
    "        val_proba = torch.softmax(val_logits, dim=1).cpu().detach().numpy()\n",
    "        val_acc = accuracy_score(y_val, val_pred)\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        counter = 0\n",
    "        torch.save(model.state_dict(), f\"best_model_seed{seed}.pt\")\n",
    "        best_val_pred = val_pred\n",
    "        best_val_proba = val_proba\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    if counter >= patience:\n",
    "        break\n",
    "\n",
    "model.load_state_dict(torch.load(f\"best_model_seed{seed}.pt\"))\n",
    "model.eval()\n",
    "\n",
    "y_val_pred = best_val_pred\n",
    "y_val_proba = best_val_proba\n",
    "\n",
    "print(\"Accuracy :\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Precision:\", precision_score(y_val, y_val_pred, average=\"macro\"))\n",
    "print(\"Recall   :\", recall_score(y_val, y_val_pred, average=\"macro\"))\n",
    "print(\"F1 Score :\", f1_score(y_val, y_val_pred, average=\"macro\"))\n",
    "try:\n",
    "    auc_val = roc_auc_score(y_val, y_val_proba, multi_class=\"ovr\", average=\"macro\")\n",
    "    print(\"AUC      :\", auc_val)\n",
    "except:\n",
    "    print(\"AUC      : Only supports binary classification or One-vs-Rest multi-classification\")\n",
    "\n",
    "print(\"confusion matrix: \\n\", confusion_matrix(y_val, y_val_pred))\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_test_logits = model(X_test_tensor)\n",
    "    y_test_pred = y_test_logits.argmax(dim=1).cpu().detach().numpy()\n",
    "    y_test_proba = torch.softmax(y_test_logits, dim=1).cpu().detach().numpy()\n",
    "\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_test_pred, average=\"macro\"))\n",
    "print(\"Recall   :\", recall_score(y_test, y_test_pred, average=\"macro\"))\n",
    "print(\"F1 Score :\", f1_score(y_test, y_test_pred, average=\"macro\"))\n",
    "try:\n",
    "    auc_test = roc_auc_score(y_test, y_test_proba, multi_class=\"ovr\", average=\"macro\")\n",
    "    print(\"AUC      :\", auc_test)\n",
    "except:\n",
    "    print(\"AUC      : Only supports binary classification or One-vs-Rest multi-classification\")\n",
    "\n",
    "print(\"confusion matrix: \\n\", confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248b0445-4c0c-4383-b762-8477c4ce3f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "def set_black_lines(disp):\n",
    "    ax = disp.ax_\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color('black')\n",
    "        spine.set_linewidth(1.2)\n",
    "    if hasattr(disp, 'im_') and disp.im_.colorbar is not None:\n",
    "        disp.im_.colorbar.outline.set_edgecolor('black')\n",
    "        disp.im_.colorbar.outline.set_linewidth(1.2)\n",
    "    ax.grid(False)\n",
    "\n",
    "disp_val = ConfusionMatrixDisplay.from_predictions(\n",
    "    y_val, val_pred,\n",
    "    display_labels=[\"acceptable\", \"potential\", \"unacceptable\"],\n",
    "    cmap=\"Blues\"\n",
    ")\n",
    "set_black_lines(disp_val)\n",
    "plt.title(\"Confusion Matrix (Validation Set)\", fontsize=14)\n",
    "plt.tight_layout() \n",
    "plt.savefig(\n",
    "    r\"E:\\Confusion_Matrix_Validation.png\",\n",
    "    dpi=900,\n",
    "    bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "disp_test = ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_test_pred,\n",
    "    display_labels=[\"acceptable\", \"potential\", \"unacceptable\"],\n",
    "    cmap=\"Blues\"\n",
    ")\n",
    "set_black_lines(disp_test)\n",
    "plt.title(\"Confusion Matrix (Test Set)\", fontsize=14)\n",
    "plt.tight_layout() \n",
    "plt.savefig(\n",
    "    r\"E:\\Confusion_Matrix_Test.png\",\n",
    "    dpi=900,\n",
    "    bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba656b3e-cbe2-4962-8fc2-2d097d34f622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "new_data_path = r\"E:\\LCMs_1431_desc.csv\"\n",
    "new_data = pd.read_csv(new_data_path)\n",
    "\n",
    "selected_features = [\n",
    "    \"ALogP\", \"AMR\", \"apol\",  \"ATSC2c\",\n",
    "    \"ATSC6m\", \"ATSC7m\", \"ATSC6i\",\n",
    "    \"GATS3c\", \"VE1_DzZ\", \"VR1_DzZ\", \"VE1_Dzp\", \"VE3_Dt\", \"MDEC-22\", \n",
    "    \"PetitjeanNumber\", \"JGI10\", \"VR1_D\"\n",
    "]\n",
    "\n",
    "missing_cols = [col for col in selected_features if col not in new_data.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"The new data is missing these characteristic columns:{missing_cols}\")\n",
    "\n",
    "new_features = new_data[selected_features]\n",
    "\n",
    "arr = new_features.values\n",
    "arr_clipped = np.clip(arr, train_min, train_max)  \n",
    "new_features_scaled = scaler.transform(arr_clipped)\n",
    "\n",
    "X_new = new_features_scaled\n",
    "df = new_data.copy()\n",
    "\n",
    "new_features_tensor = torch.tensor(new_features_scaled, dtype=torch.float32)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(new_features_tensor)            \n",
    "    probs = torch.softmax(logits, dim=1).numpy()    \n",
    "    preds = probs.argmax(axis=1)                  \n",
    "\n",
    "label_map = {0: \"acceptable\", 1: \"potential\", 2: \"unacceptable\"}\n",
    "pred_labels = [label_map[i] for i in preds]\n",
    "\n",
    "df[\"Predicted_Category\"] = pred_labels\n",
    "for i, cls in label_map.items():\n",
    "    df[f\"Prob_{cls}\"] = probs[:, i]\n",
    "\n",
    "output_path = r\"E:\\LCMs_1431_Predicted_Category(final).csv\"\n",
    "df.to_csv(output_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(df[[\"Name\", \"Predicted_Category\"] + [f\"Prob_{c}\" for c in label_map.values()]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4243ed5-b65a-4b8b-9713-9322941bb3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "sns.set(style=\"white\") \n",
    "\n",
    "def model_predict(x_numpy):\n",
    "    \"\"\"Define the model prediction function: input numpy, output softmax probability\"\"\"\n",
    "    x = np.asarray(x_numpy, dtype=np.float32)\n",
    "    with torch.no_grad():\n",
    "        out = model(torch.tensor(x))\n",
    "        return torch.softmax(out, dim=1).cpu().numpy()\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "N_SHAP = len(X_new)\n",
    "sample_idx = rng.choice(len(X_new), size=N_SHAP, replace=False)\n",
    "X_shap = X_new[sample_idx]\n",
    "\n",
    "explainer = shap.Explainer(model_predict, X_new, algorithm=\"permutation\")\n",
    "shap_values = explainer(X_shap)\n",
    "\n",
    "vals = getattr(shap_values, \"values\", None)\n",
    "if vals is None:\n",
    "    vals = np.array(shap_values)\n",
    "n_samples, n_features, n_classes = vals.shape\n",
    "\n",
    "save_dir = r\"E:\\classification\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "max_classes_to_plot = 3\n",
    "for cls_idx, cls_name in list(label_map.items())[:max_classes_to_plot]:\n",
    "    shap_vals_one = vals[:, :, cls_idx]\n",
    "    shap.summary_plot(\n",
    "        shap_vals_one,\n",
    "        X_shap,\n",
    "        feature_names=selected_features,\n",
    "        show=False,\n",
    "        plot_type=\"dot\",\n",
    "        max_display=20\n",
    "    )\n",
    "\n",
    "    plt.title(f\"SHAP Beeswarm â€“ Class: {cls_name}\", fontname=\"Times New Roman\")\n",
    "    plt.grid(False)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    save_path = os.path.join(save_dir, f\"SHAP_Beeswarm_{cls_name}.png\")\n",
    "    plt.savefig(save_path, dpi=900, bbox_inches='tight')\n",
    "    plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1505057c-f43a-4eb5-8aa1-0be4bf0fb301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "mean_abs_per_class = np.mean(np.abs(vals), axis=0)   # (n_features, n_classes)\n",
    "\n",
    "feat_names = np.array(selected_features)\n",
    "df_importance = pd.DataFrame(\n",
    "    mean_abs_per_class,\n",
    "    index=feat_names,\n",
    "    columns=[label_map[c] for c in range(n_classes)]\n",
    ")\n",
    "\n",
    "topk = 20\n",
    "order = df_importance.sum(axis=1).sort_values(ascending=False).index[:topk]\n",
    "df_top = df_importance.loc[order]\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\" \n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "colors = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\"] \n",
    "\n",
    "bottom = np.zeros(len(df_top)) \n",
    "for i, cls in enumerate(df_top.columns):\n",
    "    ax.barh(df_top.index, df_top[cls], left=bottom, color=colors[i], label=cls)\n",
    "    bottom += df_top[cls].values\n",
    "\n",
    "ax.grid(False)\n",
    "\n",
    "ax.set_xlabel(\"Mean(|SHAP|)\", fontname=\"Times New Roman\")\n",
    "ax.set_title(f\"Top-{topk} Feature Importance (stacked by class)\", fontname=\"Times New Roman\")\n",
    "\n",
    "ax.legend(title=\"Class\", prop={\"family\": \"Times New Roman\"})\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(r\"E:\\importance.png\", dpi=900, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa1bd9-1d8e-4e93-9db7-a38f216f24e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
